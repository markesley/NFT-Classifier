# üîÆ NFT Classifier

Este projeto implementa um **classificador de cole√ß√µes de NFTs** usando *embeddings de linguagem* e um modelo de machine learning treinado previamente no Google Colab.  
A aplica√ß√£o final √© servida em um **servidor Flask** com interface web simples.

---

## üöÄ Pipeline do Projeto

### 1. Treinamento no Google Colab
No Colab foi feito o **treinamento e avalia√ß√£o de v√°rios classificadores** a partir das descri√ß√µes das cole√ß√µes de NFT.  

1. **Prepara√ß√£o dos dados**
   - Cada NFT possu√≠a *badges* e descri√ß√µes textuais.
   - Os textos foram processados (remo√ß√£o de stopwords, lematiza√ß√£o etc.).
   - As classes alvo s√£o **7 categorias**:  
     ```
     ['art', 'gaming', 'memberships', 'music', 'pfps', 'photography', 'virtual-worlds']
     ```

2. **Gera√ß√£o dos embeddings**
   - Foi utilizado o modelo de linguagem **`paraphrase-multilingual-MiniLM-L12-v2`** (da biblioteca `sentence-transformers`).
   - Esse modelo converte cada descri√ß√£o em um vetor de **384 dimens√µes**.
   - Esses vetores num√©ricos representam o "significado" do texto em um espa√ßo vetorial.

3. **Treinamento dos classificadores**
   - V√°rios modelos foram testados (SVM, Logistic Regression, Random Forest, etc.).
   - O **Random Forest** obteve a **melhor acur√°cia (~75%)** nos dados de valida√ß√£o.
   - Para manter consist√™ncia, os embeddings foram **normalizados** com `StandardScaler`.

4. **Exporta√ß√£o dos artefatos**
   - O modelo final (`RandomForest`), o scaler, o label encoder e as informa√ß√µes de configura√ß√£o foram salvos em arquivos:
     ```
     model.joblib
     scaler.joblib
     label_encoder.joblib
     meta.json
     ```

---

### 2. Servidor Flask

A aplica√ß√£o Flask carrega os artefatos salvos e exp√µe um endpoint para classifica√ß√£o.

1. **Carregamento dos artefatos**
   - O `RandomForest`, `StandardScaler` e `LabelEncoder` s√£o carregados com `joblib`.
   - O `meta.json` indica qual modelo de embedding deve ser utilizado (garante compatibilidade).

2. **Fluxo de predi√ß√£o**
   - O usu√°rio envia uma descri√ß√£o de NFT (`descricao`).
   - Essa descri√ß√£o √© convertida em embedding com o mesmo modelo usado no treino.
   - O vetor √© transformado pelo `StandardScaler` (normaliza√ß√£o).
   - O `RandomForest` gera probabilidades (`predict_proba`) para cada uma das 7 classes.
   - As classes s√£o ordenadas da maior para a menor probabilidade.
   - O resultado retorna:
     - A **classe mais prov√°vel** (`predicao`).
     - As **Top K classes mais pr√≥ximas** com suas probabilidades (`top_k`).

3. **Endpoint principal**
   - `GET /` ‚Üí retorna a p√°gina web (`index.html`).
   - `POST /predict` ‚Üí recebe `{ descricao, top_k }` e retorna JSON com predi√ß√£o.

---

### 3. Interface Web

A p√°gina web foi feita com **Bootstrap** para melhor visualiza√ß√£o:

- Campo de texto para inserir a descri√ß√£o da cole√ß√£o.
- Campo num√©rico para escolher o `Top K`.
- Resultado principal destacado com **badge verde**.
- Lista das Top K classes com probabilidades exibidas em forma de **lista estilizada**.

Exemplo de sa√≠da:

---

## üìä Como as m√©tricas de aproxima√ß√£o s√£o calculadas

O classificador usa o m√©todo `predict_proba` do `RandomForest`, que funciona assim:

1. Cada √°rvore de decis√£o do Random Forest "vota" em uma classe.
2. A probabilidade final √© a propor√ß√£o de votos de todas as √°rvores.
   - Exemplo: em 100 √°rvores, se 78 votarem em "pfps" ‚Üí probabilidade = 0.78 (78%).
3. O sistema retorna as probabilidades normalizadas (que somam 1.0).
4. O `np.argsort(probs)[::-1]` organiza da maior para a menor probabilidade.
5. O campo `proba_pct` √© a probabilidade multiplicada por 100 e arredondada.

Ou seja:
- **Classe predita** = a de maior probabilidade.
- **Top K** = as K classes mais prov√°veis (ordenadas).

---

## ‚ñ∂Ô∏è Como rodar localmente

1. Clone este reposit√≥rio e entre na pasta:
   ```bash
   git clone <repo>
   cd nft-classifier
2. pip install -r requirements.txt

3. Coloque os arquivos do modelo dentro da pasta data/:

4. python app.py
